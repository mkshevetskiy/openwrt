From 0343b5c2a754ca20f5155a8f3c6d58e887b9dd4f Mon Sep 17 00:00:00 2001
From: Christian Marangi <ansuelsmth@gmail.com>
Date: Tue, 20 May 2025 16:32:31 +0200
Subject: [PATCH] net: airoha: Fix spurious Airoha Ethernet stall

It was reported that sometimes the Airoha Ethernet driver stall and a
reset is needed to actually receive packet.

This seems to be related in the logic with how the CPU and DMA counter
are handled for the RX path. The problem seems to be more evident when
multiple device are connected to the Ethernet port.

To handle this, drop local tracking of the current CPU/DMA counter and
base everything on the current register by reading them and using the
descriptor directly.

Fixes: ee0f4afa982e ("net: airoha: Add Airoha Ethernet driver")
Signed-off-by: Christian Marangi <ansuelsmth@gmail.com>
---
 drivers/net/airoha_eth.c | 32 +++++++++++++++++---------------
 1 file changed, 17 insertions(+), 15 deletions(-)

diff --git a/drivers/net/airoha_eth.c b/drivers/net/airoha_eth.c
index d894d82ff3d..de8b76da66e 100644
--- a/drivers/net/airoha_eth.c
+++ b/drivers/net/airoha_eth.c
@@ -267,7 +267,6 @@ struct airoha_qdma_fwd_desc {
 
 struct airoha_queue {
 	struct airoha_qdma_desc *desc;
-	u16 head;
 
 	int ndesc;
 };
@@ -428,7 +427,6 @@ static int airoha_qdma_init_rx_queue(struct airoha_queue *q,
 	unsigned long dma_addr;
 
 	q->ndesc = ndesc;
-	q->head = 0;
 
 	q->desc = dma_alloc_coherent(q->ndesc * sizeof(*q->desc), &dma_addr);
 	if (!q->desc)
@@ -447,7 +445,7 @@ static int airoha_qdma_init_rx_queue(struct airoha_queue *q,
 	airoha_qdma_rmw(qdma, REG_RX_CPU_IDX(qid), RX_RING_CPU_IDX_MASK,
 			FIELD_PREP(RX_RING_CPU_IDX_MASK, q->ndesc - 1));
 	airoha_qdma_rmw(qdma, REG_RX_DMA_IDX(qid), RX_RING_DMA_IDX_MASK,
-			FIELD_PREP(RX_RING_DMA_IDX_MASK, q->head));
+			FIELD_PREP(RX_RING_DMA_IDX_MASK, 0));
 
 	return 0;
 }
@@ -475,7 +473,6 @@ static int airoha_qdma_init_tx_queue(struct airoha_queue *q,
 	unsigned long dma_addr;
 
 	q->ndesc = size;
-	q->head = 0;
 
 	q->desc = dma_alloc_coherent(q->ndesc * sizeof(*q->desc), &dma_addr);
 	if (!q->desc)
@@ -486,9 +483,9 @@ static int airoha_qdma_init_tx_queue(struct airoha_queue *q,
 
 	airoha_qdma_wr(qdma, REG_TX_RING_BASE(qid), dma_addr);
 	airoha_qdma_rmw(qdma, REG_TX_CPU_IDX(qid), TX_RING_CPU_IDX_MASK,
-			FIELD_PREP(TX_RING_CPU_IDX_MASK, q->head));
+			FIELD_PREP(TX_RING_CPU_IDX_MASK, 0));
 	airoha_qdma_rmw(qdma, REG_TX_DMA_IDX(qid), TX_RING_DMA_IDX_MASK,
-			FIELD_PREP(TX_RING_DMA_IDX_MASK, q->head));
+			FIELD_PREP(TX_RING_DMA_IDX_MASK, 0));
 
 	return 0;
 }
@@ -819,8 +816,10 @@ static int airoha_eth_send(struct udevice *dev, void *packet, int length)
 
 	qid = 0;
 	q = &qdma->q_tx[qid];
-	desc = &q->desc[q->head];
-	index = (q->head + 1) % q->ndesc;
+
+	index = airoha_qdma_rr(qdma, REG_TX_CPU_IDX(qid));
+	desc = &q->desc[index];
+	index = (index + 1) % q->ndesc;
 
 	fport = 1;
 
@@ -855,7 +854,6 @@ static int airoha_eth_send(struct udevice *dev, void *packet, int length)
 	if (!(desc->ctrl & QDMA_DESC_DONE_MASK))
 		return -EAGAIN;
 
-	q->head = index;
 	airoha_qdma_rmw(qdma, REG_IRQ_CLEAR_LEN(0),
 			IRQ_CLEAR_LEN_MASK, 1);
 
@@ -868,12 +866,15 @@ static int airoha_eth_recv(struct udevice *dev, int flags, uchar **packetp)
 	struct airoha_qdma *qdma = &eth->qdma[0];
 	struct airoha_qdma_desc *desc;
 	struct airoha_queue *q;
+	int qid, index;
 	u16 length;
-	int qid;
 
 	qid = 0;
 	q = &qdma->q_rx[qid];
-	desc = &q->desc[q->head];
+
+	index = airoha_qdma_rr(qdma, REG_RX_CPU_IDX(qid));
+	index = (index + 1) % q->ndesc;
+	desc = &q->desc[index];
 
 	dma_unmap_single(virt_to_phys(desc), sizeof(*desc),
 			 DMA_FROM_DEVICE);
@@ -895,7 +896,7 @@ static int arht_eth_free_pkt(struct udevice *dev, uchar *packet, int length)
 	struct airoha_eth *eth = dev_get_priv(dev);
 	struct airoha_qdma *qdma = &eth->qdma[0];
 	struct airoha_queue *q;
-	int qid;
+	int qid, index;
 
 	if (!packet)
 		return 0;
@@ -905,11 +906,12 @@ static int arht_eth_free_pkt(struct udevice *dev, uchar *packet, int length)
 
 	dma_map_single(packet, length, DMA_TO_DEVICE);
 
-	airoha_qdma_reset_rx_desc(q, q->head, packet);
+	index = airoha_qdma_rr(qdma, REG_RX_DMA_IDX(qid));
+	airoha_qdma_reset_rx_desc(q, index, packet);
 
+	index = (index + 1) % q->ndesc;
 	airoha_qdma_rmw(qdma, REG_RX_CPU_IDX(qid), RX_RING_CPU_IDX_MASK,
-			FIELD_PREP(RX_RING_CPU_IDX_MASK, q->head));
-	q->head = (q->head + 1) % q->ndesc;
+			FIELD_PREP(RX_RING_CPU_IDX_MASK, index));
 
 	return 0;
 }
-- 
2.48.1

